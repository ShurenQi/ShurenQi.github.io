<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<!-- saved from url=(0024)https://vcc.tech/Di_Lin/ -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" class="gr__vcc_tech"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="shortcut icon" href="https://vcc.tech/Di_Lin/myIcon.ico">

<meta name="description" content="Di Lin&#39;s home page">
<link rel="stylesheet" href="./shuren_files/jemdoc.css" type="text/css">
<title>Shuren Qi</title>
<script type="text/javascript" async="" src="./shuren_files/ga.js.‰∏ãËΩΩ"></script><script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-39824124-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

</head>
<body data-gr-c-s-loaded="true">
<body style="font-family:Book Antiqua;">
<div id="layout-content" style="margin-top:25px">
<h1>Shuren Qi @ NUAA</h1>
<div id="layout-content" style="margin-top:25px">
<table>
	<tbody>
		<tr>
			<td width="1001">
				<table>
				<tbody>
	  			<tr>
				<td width="100"> <p><img src="./shuren_files/shuren2022.jpg" width="300px" style="box-shadow: 4px 4px 8px #888" /></p></td>
				<td width="50">
				<p>
					<td align="left"><b><font size="+3" face="STKaiti">Á•ÅÊ†ë‰ªÅ</font></b><br />
					<b><font size="+2" face="STKaiti">Shuren Qi &nbsp;(S. Qi)</font></b><br />
					<p><br>
					Ph.D. Student<br>
					<a " href="http://cs.nuaa.edu.cn/">College of Computer Science and Technology</a><br>
					<a " href="http://www.nuaa.edu.cn/">Nanjing University of Aeronautics and Astronautics</a><br>
					Nanjing 211106, China</p>
					<p><br>
				
				<a " href="mailto:shurenqi@nuaa.edu.cn">shurenqi@nuaa.edu.cn</a>
				&nbsp | &nbsp
				<a " href="mailto:i@srqi.email">i@srqi.email</a>
				</p>
				<a " href="https://scholar.google.com/citations?user=U4UPvlkAAAAJ&hl=en">Google Scholar</a>
				&nbsp | &nbsp
				<a " href="https://dblp.uni-trier.de/pers/hd/q/Qi:Shu=Ren">DBLP</a>
				&nbsp | &nbsp
				<a " href="https://github.com/ShurenQi">Github</a>
				</td><td width="0"></td>
				</td>
	  			</tr>
	  			</tbody></table>
	  </tr><td>	
	<td width="10"></tbody>
</table>

<h2>üî•News</h2>
<ul>
<li>Hello, I am actively looking for academic job opportunities, especially Postdoc positions on the topics of invariance, robustness, and explainability, starting from Summer 2024. If you have a suitable opportunity, please feel free to contact me and request my Curriculum Vitae!
</li>
</ul>

<h2>üë®‚ÄçüéìAbout Me</h2>
<ul>
<li>I am currently a third year Ph.D. student under the supervision of <a href="https://scholar.google.com/citations?user=KTrrZ6IAAAAJ&hl=zh-CN">Prof. Yushu Zhang</a> at <a " href="http://www.nuaa.edu.cn/">
Nanjing University of Aeronautics and Astronautics</a> (NUAA), Nanjing, China. Before that, I got my B.A. and M.S. degrees both from Liaoning Normal University, Dalian, China, in 2017 and 2020, respectively.
</li>
<li>My research focuses on <b>invariant feature extraction</b> and <b>visual signal representation</b> for 
<b>robust pattern recognition</b> and <b>visual-content forensics/security</b> applications. My current work lies in the mathematical foundations of low-level visual tasks, 
especially the theory and implementation of <b>moments and moment invariants</b>. Such methods are generic in their nature, leading to potential uses in small-scale robust or explainable vision problems.
</li>
<li>My research work has appeared in several top-tier venues of above areas, e.g., <b>ACM Computing Surveys</b>, <b>IEEE TPAMI</b>, <b>IEEE TIFS</b>, <b>IEEE TNNLS</b>, <b>ACM TOMM</b>, <b>IEEE TBD</b>, and <b>Pattern Recognition</b>, mainly as first or corresponding author.
</li>
<li>I am a recipient of the 3rd-class of Science and Technology Progress Prize from Government of Liaoning Province in 2020 and a reviewer for IEEE Transactions on Image Processing (TIP).
</li>
</ul>

<h2>üìäTop Five Representative Papers</h2>
 <ul> 
    <li><a href="https://dl.acm.org/doi/10.1145/3479428"><font size = "4">A survey of orthogonal moments for image representation: Theory, implementation, and evaluation.</font><br></a> 
	<font color= #FF6A00>Shuren Qi</font>, Yushu Zhang, Chao Wang, Jiantao Zhou, and Xiaochun Cao. <br>
    ACM Computing Surveys (<b>CSUR</b>, CORE A+), 2021.<br> 
    [<a href="https://arxiv.org/abs/2103.14799">arXiv</a>] [<a href="https://github.com/ShurenQi/MomentToolbox">code</a>] [<a href="https://mp.weixin.qq.com/s/ymAAzMQbWbKyuWz_r0wDBQ">short introduction</a>]
	[<a href="https://zhuanlan.zhihu.com/p/402410540">translated version</a>] [highly cited] <br>
	<i>‚ÄúA comprehensive survey of the orthogonal moments for image representation with a software package MomentToolbox for benchmarking such moments.‚Äù</i> <br>
    </li>
  
    <li><a href="https://ieeexplore.ieee.org/document/9881995/"><font size = "4">A principled design of image representation: Towards forensic tasks.</font> <br></a>
	<font color= #FF6A00>Shuren Qi</font>, Yushu Zhang, Chao Wang, Jiantao Zhou, and Xiaochun Cao. <br>
    IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>, CORE A+, CCF A), 2022.<br>
    [<a href="https://arxiv.org/abs/2203.00913">arXiv</a>] [<a href="https://github.com/ShurenQi/DIR">code</a>] [<a href="https://mp.weixin.qq.com/s/j5mn4PsRaKu7JLmp142p7g">short introduction</a>] [<a href="http://newsweb.nuaa.edu.cn/2022/0907/c738a291713/page.htm">media coverage</a>] [<a href="https://mp.weixin.qq.com/s/M6eUEF7Fyutx3ixM5fGyvg">best paper award</a>]<br>
    <i>‚ÄúA locally invariant representation from the perspectives of theory, implementation, and application.‚Äù</i> <br>
	</li>
	
	<li><a href="https://arxiv.org/abs/2301.07409"><font size = "4">Representing noisy image without denoising.</font><br></a> 
	<font color= #FF6A00>Shuren Qi</font>, Yushu Zhang, Chao Wang, Tao Xiang, Xiaochun Cao, and Yong Xiang. <br>
    Under review, 2023.<br>
    [<a href="https://arxiv.org/abs/2301.07409">arXiv</a>] [<a href="https://github.com/ShurenQi/FMR">code</a>] <br>
	<i>‚ÄúA globally invariant representation from the perspectives of theory, implementation, and application.‚Äù</i> <br>
    </li>
	
	<li><a href="https://arxiv.org/abs/2305.10856"><font size = "4">Towards an accurate and secure detector against adversarial perturbations.</font> <br></a>
	Chao Wang, <font color= #FF6A00>Shuren Qi‚úâ</font>, Zhiqiu Huang, Yushu Zhang, Rushi Lan, and Xiaochun Cao. <br>
    Under review, 2023.<br>
	<i>‚ÄúA forensic strategy for adversarial perturbation from the perspective of coefficient distribution in the time-frequency domain.‚Äù</i> <br>
	</li>
  
    <li><a href="https://ieeexplore.ieee.org/document/10129255"><font size = "4">PS-Net: A learning strategy for accurately exposing the professional Photoshop inpainting.</font> <br></a>
	Yushu Zhang, Zhibin Fu, <font color= #FF6A00>Shuren Qi‚úâ</font>, Mingfu Xue, Xiaochun Cao, and Yong Xiang. <br>
    IEEE Transactions on Neural Networks and Learning Systems (<b>TNNLS</b>, CORE A+, CCF B), 2023.<br>
	[<a href="https://mp.weixin.qq.com/s/5x_fji6lBdrUk2ULEAhqLw">short introduction</a>] <br>
	<i>‚ÄúA forensic strategy for Photoshop inpainting by looking for both digital integrity and semantic integrity.‚Äù</i> <br>
	</li>	
</ul>

<h2>üìùOther Selected Papers<div></div></h2>
 <ul>   
    <li><font color= #FF6A00>S. Qi</font>, Y. Zhang, C. Wang, et al., "<a href="https://www.mdpi.com/2227-7390/11/10/2239">Representing blurred image without deblurring</a>," in Mathematics, 2023.
    </li>
	
	<li><font color= #FF6A00>S. Qi</font>, Q. Tan, Y. Zhang, et al., "<a href="https://shurenqi.github.io/">Learning to predict forgery probability from PRNU</a>," under review, 2023.
    </li>
	
	<li>C. Wang, Z. Huang, <font color= #FF6A00>S. Qi</font>, et al., "<a href="https://ieeexplore.ieee.org/abstract/document/10007894">Shrinking the semantic gap: Spatial pooling of local moment invariants for copy-move forgery detection</a>," in IEEE Transactions on Information Forensics and Security (<b>TIFS</b>, CORE A, CCF A), 2023. [<a href="https://mp.weixin.qq.com/s/Z6GpUUguHY8yMf-IsHpkTA">short introduction</a>]
    </li>
	
	<li>Y. Zhang, N. Chen, <font color= #FF6A00>S. Qi‚úâ</font>, et al., "<a href="https://shurenqi.github.io/">Beyond colors: Exposing the recoloring manipulation over the spatial dimensions</a>," under review, 2023.
    </li>
	
	<li>Y. Zhang, Z. Fu, <font color= #FF6A00>S. Qi‚úâ</font>, et al., "<a href="https://ieeexplore.ieee.org/document/9964430">Localization of inpainting forgery with feature enhancement network</a>," in IEEE Transactions on Big Data (<b>TBD</b>), 2022.
    </li>
	
	<li>Y. Zhang, Q. Tan, <font color= #FF6A00>S. Qi‚úâ</font>, et al., "<a href="https://dl.acm.org/doi/10.1145/3548689">PRNU-based image forgery localization with deep multi-scale fusion</a>," in ACM Transactions on Multimedia Computing, Communications, and Applications (<b>TOMM</b>, CCF B), 2022. [<a href="https://mp.weixin.qq.com/s/uyl-KqAPLWN9Td2r6N6Xkw">short introduction</a>]
    </li>
	
	<li>Y. Zhang, N. Chen, <font color= #FF6A00>S. Qi‚úâ</font>, et al., "<a href="https://dl.acm.org/doi/10.1145/3571076">Detection of recolored image by texture features in chrominance components</a>," in ACM Transactions on Multimedia Computing, Communications, and Applications (<b>TOMM</b>, CCF B), 2022.
    </li>
	
	<li>Q. Tan, <font color= #FF6A00>S. Qi</font>, Y. Zhang, et al., "<a href="https://ieeexplore.ieee.org/abstract/document/9949586">PRNU-based image forgery localization with convolutional neural network</a>," in International Workshop on Multimedia Signal Processing (<b>MMSP</b>, CORE B), 2022.
    </li>
		
	<li>H. Yang, <font color= #FF6A00>S. Qi‚Ä†</font>, J. Tian, et al., "<a href="https://doi.org/10.1016/j.patcog.2021.107898">Robust and discriminative image representation: Fractional-order Jacobi-Fourier moments</a>," in Pattern Recognition (<b>PR</b>, CORE A+, CCF B), 2021. [<a href="https://github.com/ShurenQi/FJFM">code</a>]
    </li>
	
	<li>H. Yang, <font color= #FF6A00>S. Qi‚Ä†</font>, C. Wang, et al., "<a href="https://doi.org/10.1016/j.patcog.2019.107177">Image analysis by log-polar Exponent-Fourier moments</a>," in Pattern Recognition (<b>PR</b>, CORE A+, CCF B), 2020.
    </li>
	
	<li>H. Yang, <font color= #FF6A00>S. Qi‚Ä†</font>, P. Niu, et al., "<a href="https://doi.org/10.1016/j.image.2019.115747">Color image zero-watermarking based on fast quaternion generic polar complex exponential transform</a>," in Signal Processing: Image Communication (<b>SPIC</b>), 2020. [<a href="https://www.journals.elsevier.com/signal-processing-image-communication/most-cited-articles">most cited articles 2020-2023 (20 in SPIC)</a>] [<a href="https://github.com/ShurenQi/FGPCET">code</a>]
    </li>
	
	<li>H. Yang, <font color= #FF6A00>S. Qi‚Ä†</font>, Y. Niu, et al., "<a href="https://link.springer.com/article/10.1007/s11042-019-08169-w">Copy-move forgery detection based on adaptive keypoints extraction and matching</a>," in Multimedia Tools and Applications (<b>MTAP</b>), 2019.
    </li>
<!--	
	
	
	
-->
    <div align="right">‚úâ as corresponding author<br></div>
	<div align="right">‚Ä† as 2nd author and 1st author is my supervisor</div>	
</ul>
              
<div id="footer"> </div>
<br>
<center><a href="https://info.flagcounter.com/oSWA"><img src="https://s11.flagcounter.com/mini/oSWA/bg_FFFFFF/txt_000000/border_C2C2C2/flags_0/" alt="Flag Counter" border="0"></a></center>

</body></html>
